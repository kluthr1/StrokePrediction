{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import datetime \n",
    "import numpy as np \n",
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from os.path import isfile, join \n",
    "from os import listdir \n",
    "from random import shuffle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkBuilder: \n",
    "    def __init__(self): \n",
    "        pass\n",
    "    def attach_conv_layer(self, input_layer, output_size=32, feature_size=(5, 5), strides=[1, 1, 1, 1], padding='SAME',\n",
    "                          summary=False):\n",
    "        with tf.name_scope(\"Convolution\") as scope:\n",
    "            input_size = input_layer.get_shape().as_list()[-1]\n",
    "            weights = tf.Variable(tf.random_normal([feature_size[0], feature_size[1], input_size, output_size]), name='conv_weights')\n",
    "            if summary:\n",
    "                tf.summary.histogram(weights.name, weights)\n",
    "            biases = tf.Variable(tf.random_normal([output_size]),name='conv_biases')\n",
    "            conv = tf.nn.conv2d(input_layer, weights, strides=strides, padding=padding)+biases\n",
    "            return conv\n",
    "    def attach_pooling_layer(self, input_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME'):\n",
    "        with tf.name_scope(\"Pooling\") as scope:\n",
    "            return tf.nn.max_pool(input_layer, ksize=ksize, strides=strides, padding=padding)\n",
    "    def attach_relu_layer(self, input_layer):\n",
    "        with tf.name_scope(\"Activation\") as scope:\n",
    "            return tf.nn.relu(input_layer)\n",
    "\n",
    "    def attach_sigmoid_layer(self, input_layer):\n",
    "        with tf.name_scope(\"Activation\") as scope:\n",
    "            return tf.nn.sigmoid(input_layer)\n",
    "\n",
    "    def attach_softmax_layer(self, input_layer):\n",
    "        with tf.name_scope(\"Activation\") as scope:\n",
    "            return tf.nn.softmax(input_layer)\n",
    "    \n",
    "    def flatten(self, input_layer):\n",
    "        with tf.name_scope(\"Flatten\") as scope:\n",
    "            input_size = input_layer.get_shape().as_list()\n",
    "            new_size = input_size[-1]*input_size[-2]*input_size[-3]\n",
    "            return tf.reshape(input_layer, [-1, new_size])\n",
    "\n",
    "    def attach_dense_layer(self, input_layer, size, summary=False):\n",
    "        with tf.name_scope(\"Dense\") as scope:\n",
    "            input_size = input_layer.get_shape().as_list()[-1]\n",
    "            weights = tf.Variable(tf.random_normal([input_size, size]), name='dense_weigh')\n",
    "            if summary:\n",
    "                tf.summary.histogram(weights.name, weights)\n",
    "            biases = tf.Variable(tf.random_normal([size]), name='dense_biases')\n",
    "            dense = tf.matmul(input_layer, weights) + biases\n",
    "            return dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSetGenerator:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_labels = self.get_data_labels()\n",
    "        self.data_info = self.get_data_paths()\n",
    "\n",
    "    def get_data_labels(self):\n",
    "        data_labels = []\n",
    "        for filename in listdir(self.data_dir):\n",
    "            if not isfile(join(self.data_dir, filename)):\n",
    "                data_labels.append(filename)\n",
    "        return data_labels\n",
    "\n",
    "    def get_data_paths(self):\n",
    "        data_paths = []\n",
    "        for label in self.data_labels:\n",
    "            img_lists=[]\n",
    "            path = join(self.data_dir, label)\n",
    "            for filename in listdir(path):\n",
    "                tokens = filename.split('.')\n",
    "                if tokens[-1] == 'png':\n",
    "                    image_path=join(path, filename)\n",
    "                    img_lists.append(image_path)\n",
    "            shuffle(img_lists)\n",
    "            data_paths.append(img_lists)\n",
    "        return data_paths\n",
    "     # to save the labels its optional incase you want to restore the names from the ids \n",
    "    # and you forgot the names or the order it was generated \n",
    "    def save_labels(self, path):\n",
    "        pickle.dump(self.data_labels, open(path,\"wb\"))\n",
    "\n",
    "    def get_mini_batches(self, batch_size=10, image_size=(200, 200), allchannel=True):\n",
    "        images = []\n",
    "        labels = []\n",
    "        empty=False\n",
    "        counter=0\n",
    "        each_batch_size=int(batch_size/len(self.data_info))\n",
    "        while True:\n",
    "            for i in range(len(self.data_labels)):\n",
    "                label = np.zeros(len(self.data_labels),dtype=int)\n",
    "                label[i] = 1\n",
    "                if len(self.data_info[i]) < counter+1:\n",
    "                    empty=True\n",
    "                    continue\n",
    "                empty=False\n",
    "                img = cv2.imread(self.data_info[i][counter])\n",
    "                img = self.resizeAndPad(img, image_size)\n",
    "                if not allchannel:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    img = np.reshape(img, (1, img.shape[0], img.shape[1], 1))\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "            if empty:\n",
    "                break\n",
    "            # if the iterator is multiple of batch size return the mini batch\n",
    "            if (counter)%each_batch_size == 0:\n",
    "                yield np.array(images,dtype=np.uint8), np.array(labels,dtype=np.uint8)\n",
    "                del images\n",
    "                del labels\n",
    "                images=[]\n",
    "                labels=[]\n",
    "\n",
    "    def resizeAndPad(self, img, size):\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        sh, sw = size\n",
    "        # interpolation method\n",
    "        if h > sh or w > sw:  # shrinking image\n",
    "            interp = cv2.INTER_AREA\n",
    "        else: # stretching image\n",
    "            interp = cv2.INTER_CUBIC\n",
    "\n",
    "        # aspect ratio of image\n",
    "        aspect = w/h\n",
    "\n",
    "        # padding\n",
    "        if aspect > 1: # horizontal image\n",
    "            new_shape = list(img.shape)\n",
    "            new_shape[0] = w\n",
    "            new_shape[1] = w\n",
    "            new_shape = tuple(new_shape)\n",
    "            new_img=np.zeros(new_shape, dtype=np.uint8)\n",
    "            h_offset=int((w-h)/2)\n",
    "            new_img[h_offset:h_offset+h, :, :] = img.copy()\n",
    "\n",
    "        elif aspect < 1: # vertical image\n",
    "            new_shape = list(img.shape)\n",
    "            new_shape[0] = h\n",
    "            new_shape[1] = h\n",
    "            new_shape = tuple(new_shape)\n",
    "            new_img = np.zeros(new_shape,dtype=np.uint8)\n",
    "            w_offset = int((h-w) / 2)\n",
    "            new_img[:, w_offset:w_offset + w, :] = img.copy()\n",
    "        else:\n",
    "            new_img = img.copy()\n",
    "        # scale and pad\n",
    "        scaled_img = cv2.resize(new_img, size, interpolation=interp)\n",
    "        return scaled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
